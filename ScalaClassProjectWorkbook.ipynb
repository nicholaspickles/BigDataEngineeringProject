{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b53585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.0.0`;\n",
    "import org.apache.log4j.{Level, Logger};\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF);\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = SparkSession.\n",
    "            builder().\n",
    "            appName(\"scala-spark-notebook\").\n",
    "            master(\"spark://spark-master:7077\").\n",
    "            config(\"spark.executor.memory\", \"512m\").\n",
    "            getOrCreate()\n",
    "\n",
    "//df=spark.read.format(\"csv\").option(\"header\",\"true\").load(\"/AirlineData/flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180b641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres1\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"3.0.0\"\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0965944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36maircraft_dataDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [aircraft_code: string, model: string ... 1 more field]\n",
       "\u001b[36mairport_dataDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [airport_code: string, airport_name: string ... 4 more fields]\n",
       "\u001b[36mboarding_passesDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [ticket_no: string, flight_id: string ... 2 more fields]\n",
       "\u001b[36mbookingsDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [book_ref: string, book_date: string ... 1 more field]\n",
       "\u001b[36mflightDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [flight_id: int, flight_no: int ... 8 more fields]\n",
       "\u001b[36mseatsDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [aircraft_code: string, seat_no: string ... 1 more field]\n",
       "\u001b[36mticket_flightsDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [ticket_no: string, flight_id: int ... 2 more fields]\n",
       "\u001b[36mticketsDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [ticket_no: string, book_ref: string ... 3 more fields]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val aircraft_dataDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/data/aircrafts_data.csv\")\n",
    "val airport_dataDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/data/airports_data.csv\")\n",
    "val boarding_passesDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/data/boarding_passes.csv\")\n",
    "val bookingsDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/data/bookings.csv\")\n",
    "val flightDF = spark.read.format(\"csv\").option(\"header\", \"false\").schema(\"flight_id int, flight_no int, scheduled_departure timestamp, scheduled_arrival timestamp, departure_airport string, arrival_airport string, status string, aircraft_code string, actual_departure timestamp, actual_arrival timestamp\").load(\"/data/flights.csv\")\n",
    "val seatsDF = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/data/seats.csv\")\n",
    "val ticket_flightsDF = spark.read.format(\"csv\").option(\"header\", \"false\").schema(\"ticket_no string, flight_id int, fare_conditions string, amount int\").load(\"/data/ticket_flights.csv\")\n",
    "val ticketsDF = spark.read.format(\"csv\").option(\"header\", \"false\").schema(\"ticket_no string, book_ref string, passenger_id string, passenger_name string, contact_data string\").load(\"/data/tickets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c143b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|flight_ID|sum(amount)|\n",
      "+---------+-----------+\n",
      "|     2122|    2592100|\n",
      "|    18979|     441900|\n",
      "|     5518|    2483700|\n",
      "|     7833|     564700|\n",
      "|    14832|     124700|\n",
      "|    15447|    1501300|\n",
      "|    29834|     113400|\n",
      "|     4101|      90000|\n",
      "|    29194|     916300|\n",
      "|    15727|    1065200|\n",
      "|     2366|   16470100|\n",
      "|     6654|     138200|\n",
      "|    10206|      58000|\n",
      "|    12027|     113400|\n",
      "|    15790|     268100|\n",
      "|    26708|     539800|\n",
      "|      463|    1436100|\n",
      "|     7754|    5478700|\n",
      "|     7554|     308300|\n",
      "|    28577|     850200|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//ticket_flightsDF.show()\n",
    "ticket_flightsDF.groupBy(\"flight_ID\").sum(\"amount\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad046eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12.10",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
